"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[2817],{3905:(e,t,n)=>{n.r(t),n.d(t,{MDXContext:()=>m,MDXProvider:()=>c,mdx:()=>b,useMDXComponents:()=>u,withMDXComponents:()=>s});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function d(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var m=a.createContext({}),s=function(e){return function(t){var n=u(t.components);return a.createElement(e,o({},t,{components:n}))}},u=function(e){var t=a.useContext(m),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},c=function(e){var t=u(e.components);return a.createElement(m.Provider,{value:t},e.children)},p="mdxType",x={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},g=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,m=d(e,["components","mdxType","originalType","parentName"]),s=u(n),c=r,p=s["".concat(i,".").concat(c)]||s[c]||x[c]||o;return n?a.createElement(p,l(l({ref:t},m),{},{components:n})):a.createElement(p,l({ref:t},m))}));function b(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=g;var l={};for(var d in t)hasOwnProperty.call(t,d)&&(l[d]=t[d]);l.originalType=e,l[p]="string"==typeof e?e:r,i[1]=l;for(var m=2;m<o;m++)i[m]=n[m];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}g.displayName="MDXCreateElement"},67050:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>l,toc:()=>m});var a=n(87462),r=(n(67294),n(3905));const o={sidebar_position:50,title:"Data Format"},i="Data Format",l={unversionedId:"open_datasets/aria_digital_twin_dataset/data_format",id:"open_datasets/aria_digital_twin_dataset/data_format",title:"Data Format",description:"Sequence and Subsequence",source:"@site/docs/open_datasets/aria_digital_twin_dataset/data_format.mdx",sourceDirName:"open_datasets/aria_digital_twin_dataset",slug:"/open_datasets/aria_digital_twin_dataset/data_format",permalink:"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/data_format",draft:!1,editUrl:"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/open_datasets/aria_digital_twin_dataset/data_format.mdx",tags:[],version:"current",sidebarPosition:50,frontMatter:{sidebar_position:50,title:"Data Format"},sidebar:"tutorialSidebar",previous:{title:"Advanced Tutorials",permalink:"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/advanced_tutorials"},next:{title:"Data Loader",permalink:"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/data_loader"}},d={},m=[{value:"Sequence and Subsequence",id:"sequence-and-subsequence",level:2},{value:"Ground Truth Data",id:"ground-truth-data",level:2},{value:"Skeleton Data and Availability",id:"skeleton-data-and-availability",level:2},{value:"Format of Ground Truth Data",id:"format-of-ground-truth-data",level:2},{value:"2d_bounding_box.csv (or 2d_bounding_box_with_skeleton).csv",id:"2d_bounding_boxcsv-or-2d_bounding_box_with_skeletoncsv",level:3},{value:"3d_bounding_box.csv",id:"3d_bounding_boxcsv",level:3},{value:"aria_trajectory.csv",id:"aria_trajectorycsv",level:3},{value:"eyegaze.csv",id:"eyegazecsv",level:3},{value:"scene_objects.csv",id:"scene_objectscsv",level:3},{value:"instances.json",id:"instancesjson",level:3},{value:"Skeleton_T.json or Skeleton_C.json",id:"skeleton_tjson-or-skeleton_cjson",level:3},{value:"SkeletonMetaData.json",id:"skeletonmetadatajson",level:3}],s={toc:m},u="wrapper";function c(e){let{components:t,...n}=e;return(0,r.mdx)(u,(0,a.Z)({},s,n,{components:t,mdxType:"MDXLayout"}),(0,r.mdx)("h1",{id:"data-format"},"Data Format"),(0,r.mdx)("h2",{id:"sequence-and-subsequence"},"Sequence and Subsequence"),(0,r.mdx)("p",null,"A sequence in ADT represents a data recording in a scene. It can be either a multi-person activity,\nwhich may include multiple Aria devices recording at the same time, or a single-person activity, which includes only one Aria device.\nInside a sequence, we use subsequences to represent the recording of each Aria device and its associated ground truth data.\nSo far, an ADT sequence contains at most 2 subsequences. Each sequence has the following folder structure:"),(0,r.mdx)("pre",null,(0,r.mdx)("code",{parentName:"pre"},"|SequenceName|\n-----|Subsequence1Name|\n-----|Subsequence2Name| [Optional] # Omitted if a sequence is a single person activity\n-----|metadata.json\n")),(0,r.mdx)("p",null,"The metadata.json file contains the high-level sequence information such as the included Aria's serial number, the scene name, etc, which can be\nloaded and queried by AriaDigitalTwinDataPathProvider. Note that prior to dataset v1.1, this was named gt-metadata. Please see ",(0,r.mdx)("a",{parentName:"p",href:"https://github.com/facebookresearch/projectaria_tools/releases/tag/1.1.0"},"release_note")),(0,r.mdx)("h2",{id:"ground-truth-data"},"Ground Truth Data"),(0,r.mdx)("p",null,"You can use the AriaDigitalTwinDataPathProvider to load a sequence and select a subsequence.\nAriaDigitalTwinDataPathProvider will manage all the ground truth files (see below) in a subsequence folder."),(0,r.mdx)("pre",null,(0,r.mdx)("code",{parentName:"pre"},"|SubsequenceName|\n----video.vrs  # Aria recording data\n----instances.json  # metadata of all instances in a sequence. An instance can be an object or a skeleton\n----aria_trajectory.csv  # 6DoF Aria trajectory\n----2d_bounding_box.csv  # 2D bounding box data for instances in three Aria sensors: RGB camera, left SLAM camera, right SLAM camera\n----3d_bounding_box.csv  # 3D AABB of each object\n----scene_objects.csv    # 6 DoF poses of objects\n----eyegaze.csv          # Eye gaze\n----synthetic_video.vrs  # Synthetic rendering of video.vrs\n----depth_images.vrs     # Depth images of video.vrs\n----segmentations.vrs    # Instance segmentations of video.vrs\n----skeleton_aria_association.json [optional]  # File showing association between Aria devices and skeletons, if they exist. Omitted if a sequence does not have skeleton ground truth.\n----Skeleton_*.json [optional]   # Body skeleton data. * is the skeleton name. Omitted if a sequence does not have skeleton ground truth\n----2d_bounding_box_with_skeleton.csv [optional]  # 2D bounding box data with body mesh occlusions. Omitted if a sequence does not have skeleton ground truth\n----depth_images_with_skeleton.vrs [optional]  # Depth images with body mesh occlusions. Omitted if a sequence does not have skeleton ground truth\n----segmentations_with_skeleton.vrs [optional]  # Segmentations with body mesh occlusions. Omitted if a sequence does not have skeleton ground truth\n")),(0,r.mdx)("p",null,"Note that prior to dataset v1.1, skeleton_aria_association.json was named SkeletonMetaData.json. Please see ",(0,r.mdx)("a",{parentName:"p",href:"https://github.com/facebookresearch/projectaria_tools/releases/tag/1.1.0"},"release note")),(0,r.mdx)("h2",{id:"skeleton-data-and-availability"},"Skeleton Data and Availability"),(0,r.mdx)("p",null,"Note that not all ADT sequences have skeleton tracking.\nFor those sequences with skeleton tracking enabled, we use the marker measurements from the bodysuit to generate a 3D mesh estimate of the wearer which is then used in our ground truth\ngeneration pipeline to calculate 2D bounding boxes, segmentation images and depth images.\nIn these cases, ADT provide two sets of ground truth data: one with skeleton occlusion, one without."),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},"segmentations.vrs vs. segmentations_with_skeleton.vrs"),(0,r.mdx)("li",{parentName:"ul"},"depth_images.vrs vs. depth_images_with_skeleton.vrs"),(0,r.mdx)("li",{parentName:"ul"},"2d_bounding_box_with_skeleton.csv")),(0,r.mdx)("p",null,"You can use AriaDigitalTwinDataPathsProvider to easily switch between these two sets."),(0,r.mdx)("h2",{id:"format-of-ground-truth-data"},"Format of Ground Truth Data"),(0,r.mdx)("p",null,"Our data loader loads all this data into a single class with useful tools for accessing data.\nFor more information on the data classes returned by the loader, see this ",(0,r.mdx)("a",{parentName:"p",href:"/docs/open_datasets/aria_digital_twin_dataset/data_loader"},"section"),".\nBelow you will find more information on the above csv and json files."),(0,r.mdx)("h3",{id:"2d_bounding_boxcsv-or-2d_bounding_box_with_skeletoncsv"},"2d_bounding_box.csv (or 2d_bounding_box_with_skeleton).csv"),(0,r.mdx)("table",null,(0,r.mdx)("thead",{parentName:"table"},(0,r.mdx)("tr",{parentName:"thead"},(0,r.mdx)("th",{parentName:"tr",align:null},"Column"),(0,r.mdx)("th",{parentName:"tr",align:null},"Type"),(0,r.mdx)("th",{parentName:"tr",align:null},"Description"))),(0,r.mdx)("tbody",{parentName:"table"},(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"stream_id"),(0,r.mdx)("td",{parentName:"tr",align:null},"string"),(0,r.mdx)("td",{parentName:"tr",align:null},"camera stream id associated with the bounding box image")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"object_uid"),(0,r.mdx)("td",{parentName:"tr",align:null},"uint64_t"),(0,r.mdx)("td",{parentName:"tr",align:null},"id of the instance (object or skeleton)")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"timestamp","[ns]"),(0,r.mdx)("td",{parentName:"tr",align:null},"int64_t"),(0,r.mdx)("td",{parentName:"tr",align:null},"timestamp of the image in nanoseconds")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"x_min","[pixel]"),(0,r.mdx)("td",{parentName:"tr",align:null},"int"),(0,r.mdx)("td",{parentName:"tr",align:null},"minimum dimension in the x axis")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"x_max","[pixel]"),(0,r.mdx)("td",{parentName:"tr",align:null},"int"),(0,r.mdx)("td",{parentName:"tr",align:null},"maximum dimension in the x axis")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"y_min","[pixel]"),(0,r.mdx)("td",{parentName:"tr",align:null},"int"),(0,r.mdx)("td",{parentName:"tr",align:null},"minimum dimension in the y axis")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"y_max","[pixel]"),(0,r.mdx)("td",{parentName:"tr",align:null},"int"),(0,r.mdx)("td",{parentName:"tr",align:null},"maximum dimension in the y axis")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"visibility_ratio","[%]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"percentage of the object that is visible (0: not visible, 1: fully visible)")))),(0,r.mdx)("h3",{id:"3d_bounding_boxcsv"},"3d_bounding_box.csv"),(0,r.mdx)("table",null,(0,r.mdx)("thead",{parentName:"table"},(0,r.mdx)("tr",{parentName:"thead"},(0,r.mdx)("th",{parentName:"tr",align:null},"Column"),(0,r.mdx)("th",{parentName:"tr",align:null},"Type"),(0,r.mdx)("th",{parentName:"tr",align:null},"Description"))),(0,r.mdx)("tbody",{parentName:"table"},(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"object_uid"),(0,r.mdx)("td",{parentName:"tr",align:null},"uint64_t"),(0,r.mdx)("td",{parentName:"tr",align:null},"id of the instance (object or skeleton)")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"timestamp","[ns]"),(0,r.mdx)("td",{parentName:"tr",align:null},"int64_t"),(0,r.mdx)("td",{parentName:"tr",align:null},"timestamp of the image in nanoseconds. -1 means the instance is static")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"p_local_obj_xmin","[m]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"minimum dimension in the x axis (in meters) of the bounding box")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"p_local_obj_xmax","[m]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"maximum dimension in the x axis (in meters) of the bounding box")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"p_local_obj_ymin","[m]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"minimum dimension in the y axis (in meters) of the bounding box")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"p_local_obj_ymax","[m]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"maximum dimension in the y axis (in meters) of the bounding box")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"p_local_obj_zmin","[m]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"minimum dimension in the z axis (in meters) of the bounding box")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"p_local_obj_zmax","[m]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"maximum dimension in the z axis (in meters) of the bounding box")))),(0,r.mdx)("h3",{id:"aria_trajectorycsv"},"aria_trajectory.csv"),(0,r.mdx)("p",null,"We are using the same trajectory format as ",(0,r.mdx)("a",{parentName:"p",href:"/docs/data_formats/mps/mps_trajectory#closed-loop-trajectory"},"the closed loop trajectory in MPS"),"."),(0,r.mdx)("h3",{id:"eyegazecsv"},"eyegaze.csv"),(0,r.mdx)("p",null,"We are using the same ",(0,r.mdx)("a",{parentName:"p",href:"/docs/data_formats/mps/mps_eye_gaze#eye-gaze-data-format"},"eye gaze format as MPS"),"."),(0,r.mdx)("h3",{id:"scene_objectscsv"},"scene_objects.csv"),(0,r.mdx)("table",null,(0,r.mdx)("thead",{parentName:"table"},(0,r.mdx)("tr",{parentName:"thead"},(0,r.mdx)("th",{parentName:"tr",align:null},"Column"),(0,r.mdx)("th",{parentName:"tr",align:null},"Type"),(0,r.mdx)("th",{parentName:"tr",align:null},"Description"))),(0,r.mdx)("tbody",{parentName:"table"},(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"object_uid"),(0,r.mdx)("td",{parentName:"tr",align:null},"uint64_t"),(0,r.mdx)("td",{parentName:"tr",align:null},"id of the instance (object or skeleton)")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"timestamp","[ns]"),(0,r.mdx)("td",{parentName:"tr",align:null},"int64_t"),(0,r.mdx)("td",{parentName:"tr",align:null},"timestamp of the image in nanoseconds. -1 means the instance is static")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"t_wo_x","[m]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"x translation from object frame to world (scene) frame (in meters)")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"t_wo_y","[m]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"y translation from object frame to world (scene) frame (in meters)")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"t_wo_z","[m]"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"z translation from object frame to world (scene) frame (in meters)")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"q_wo_w"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"w component of quaternion from object frame to world (scene) frame")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"q_wo_x"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"x component of quaternion from object frame to world (scene) frame")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"q_wo_y"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"y component of quaternion from object frame to world (scene) frame")),(0,r.mdx)("tr",{parentName:"tbody"},(0,r.mdx)("td",{parentName:"tr",align:null},"q_wo_z"),(0,r.mdx)("td",{parentName:"tr",align:null},"double"),(0,r.mdx)("td",{parentName:"tr",align:null},"z component of quaternion from object frame to world (scene) frame")))),(0,r.mdx)("h3",{id:"instancesjson"},"instances.json"),(0,r.mdx)("pre",null,(0,r.mdx)("code",{parentName:"pre"},'{\n    "IID1": {\n    "instance_id": IID1,\n    "instance_name": "XXXX",\n    "prototype_name": "XXXX",\n    "category": "XXXX",\n    "category_uid": XXXX,\n    "motion_type": "static/dynamic",\n    "instance_type": "object/human",\n    "rigidity": "rigid/deformable",\n    "rotational_symmetry": {\n      "is_annotated": true/false\n    },\n    "canonical_pose": {\n      "up_vector": [\n        x,\n        y,\n        z\n      ],\n      "front_vector": [\n        x,\n        y,\n        z\n      ]\n    }\n  },\n  ...\n}\n')),(0,r.mdx)("h3",{id:"skeleton_tjson-or-skeleton_cjson"},"Skeleton_T.json or Skeleton_C.json"),(0,r.mdx)("pre",null,(0,r.mdx)("code",{parentName:"pre"},'{\n  "dt_optitrack_minus_device_ns": {\n    "1WM103600M1292": XXXXX\n  },\n  "frames": [\n    {\n      "markers": [\n        [\n          mx1\n          my1\n          mz1\n        ],\n        ...\n       ],\n       "joints": [\n         [\n          jx1\n          jy1\n          jz1\n         ],\n        ...\n       ],\n       "timestamp_ns": tsns1\n    },\n    ...\n  ]\n}\n')),(0,r.mdx)("h3",{id:"skeletonmetadatajson"},"SkeletonMetaData.json"),(0,r.mdx)("p",null,"This file shows the skeleton info including name, Id, and associated Aria device for each human in the sequence.\nSince it's possible to have a human wearing a bodysuit that does not have an Aria, it's possible to have a skeleton with no associated Aria.\nConversely, it's also possible to have an Aria wearer with no bodysuit, which means there may be an empty skeleton Id and name associated with an Aria."),(0,r.mdx)("pre",null,(0,r.mdx)("code",{parentName:"pre"},'{\n    "SkeletonMetadata": [\n        {\n            "AssociatedDeviceSerial": "AriaSerial1/NONE",\n            "SkeletonId": ID1,\n            "SkeletonName": "SkeletonName1/NONE"\n        },\n        ...\n    ]\n}\n')))}c.isMDXComponent=!0}}]);