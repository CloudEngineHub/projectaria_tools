"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[7003],{3905:(e,t,r)=>{r.r(t),r.d(t,{MDXContext:()=>c,MDXProvider:()=>l,mdx:()=>y,useMDXComponents:()=>m,withMDXComponents:()=>d});var a=r(67294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function n(){return n=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var r=arguments[t];for(var a in r)Object.prototype.hasOwnProperty.call(r,a)&&(e[a]=r[a])}return e},n.apply(this,arguments)}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function s(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function p(e,t){if(null==e)return{};var r,a,o=function(e,t){if(null==e)return{};var r,a,o={},n=Object.keys(e);for(a=0;a<n.length;a++)r=n[a],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(a=0;a<n.length;a++)r=n[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var c=a.createContext({}),d=function(e){return function(t){var r=m(t.components);return a.createElement(e,n({},t,{components:r}))}},m=function(e){var t=a.useContext(c),r=t;return e&&(r="function"==typeof e?e(t):s(s({},t),e)),r},l=function(e){var t=m(e.components);return a.createElement(c.Provider,{value:t},e.children)},u="mdxType",f={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var r=e.components,o=e.mdxType,n=e.originalType,i=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),d=m(r),l=o,u=d["".concat(i,".").concat(l)]||d[l]||f[l]||n;return r?a.createElement(u,s(s({ref:t},c),{},{components:r})):a.createElement(u,s({ref:t},c))}));function y(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var n=r.length,i=new Array(n);i[0]=h;var s={};for(var p in t)hasOwnProperty.call(t,p)&&(s[p]=t[p]);s.originalType=e,s[u]="string"==typeof e?e:o,i[1]=s;for(var c=2;c<n;c++)i[c]=r[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,r)}h.displayName="MDXCreateElement"},250:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>l,frontMatter:()=>n,metadata:()=>s,toc:()=>c});var a=r(87462),o=(r(67294),r(3905));const n={sidebar_position:70,title:"Aria Machine Perception Services (MPS)"},i=void 0,s={unversionedId:"ARK/mps/mps",id:"ARK/mps/mps",title:"Aria Machine Perception Services (MPS)",description:"To accelerate research with Project Aria, we provide several Spatial AI machine perception capabilities that forms the foundation for the future Contextualized AI applications and analysis of the egocentric data. These capabilities are powered by a set of proprietary machine perception algorithms designed for Project Aria device and provide superior accuracy and robustness on the recorded data compared to the off-the-shelf open source algorithms.",source:"@site/docs/ARK/mps/mps.mdx",sourceDirName:"ARK/mps",slug:"/ARK/mps/",permalink:"/projectaria_tools/docs/ARK/mps/",draft:!1,editUrl:"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/ARK/mps/mps.mdx",tags:[],version:"current",sidebarPosition:70,frontMatter:{sidebar_position:70,title:"Aria Machine Perception Services (MPS)"},sidebar:"tutorialSidebar",previous:{title:"Desktop Companion App",permalink:"/projectaria_tools/docs/ARK/desktop_companion_app"},next:{title:"Request MPS",permalink:"/projectaria_tools/docs/ARK/mps/request_mps"}},p={},c=[{value:"About MPS Data Loader APIs",id:"about-mps-data-loader-apis",level:2},{value:"Question &amp; Feedback",id:"question--feedback",level:2}],d={toc:c},m="wrapper";function l(e){let{components:t,...r}=e;return(0,o.mdx)(m,(0,a.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,o.mdx)("p",null,"To accelerate research with Project Aria, we provide several Spatial AI machine perception capabilities that forms the foundation for the future Contextualized AI applications and analysis of the egocentric data. These capabilities are powered by a set of proprietary machine perception algorithms designed for Project Aria device and provide superior accuracy and robustness on the recorded data compared to the off-the-shelf open source algorithms."),(0,o.mdx)("p",null,"All MPS functionalities are offered as post-processing of VRS files via a cloud service. Through the ",(0,o.mdx)("a",{parentName:"p",href:"/docs/ARK/desktop_companion_app"},"Desktop App"),", you can ",(0,o.mdx)("a",{parentName:"p",href:"/docs/ARK/mps/request_mps"},"request")," the following derived data from any VRS file that contains necessary sensor's data."),(0,o.mdx)("ul",null,(0,o.mdx)("li",{parentName:"ul"},(0,o.mdx)("p",{parentName:"li"},(0,o.mdx)("strong",{parentName:"p"},"6DoF Trajectory")," : MPS provides two types of high frequency (1kHz) trajectories: the ",(0,o.mdx)("a",{parentName:"p",href:"/docs/data_formats/mps/mps_trajectory#open-loop-trajectory"},"open loop trajectory")," that is a local odometry estimation from visual-inertial odometry (VIO); and the ",(0,o.mdx)("a",{parentName:"p",href:"/docs/data_formats/mps/mps_trajectory#closed-loop-trajectory"},"closed loop trajectory")," that is created via batch optimization, using multi-sensors' input (SLAM, IMU, barometer, WiFi and GPS), fully optimized and providing poses in a consistent frame of reference.")),(0,o.mdx)("li",{parentName:"ul"},(0,o.mdx)("p",{parentName:"li"},(0,o.mdx)("strong",{parentName:"p"},"Online sensor calibration")," : The ",(0,o.mdx)("a",{parentName:"p",href:"/docs/data_formats/mps/mps_trajectory#online-calibration"},"time-varying intrinsic and extrinsic calibrations")," of cameras and IMUs are estimated at the frequency of SLAM cameras by our multi-sensor state estimation pipeline.")),(0,o.mdx)("li",{parentName:"ul"},(0,o.mdx)("p",{parentName:"li"},(0,o.mdx)("strong",{parentName:"p"},"Semi-dense point cloud")," : The ",(0,o.mdx)("a",{parentName:"p",href:"/docs/data_formats/mps/mps_pointcloud"},"semi-dense point clouds")," are provided in MPS for researchers who need static scene 3D reconstructions, reliable 2D images tracks or a representative visualization of the environment.")),(0,o.mdx)("li",{parentName:"ul"},(0,o.mdx)("p",{parentName:"li"},(0,o.mdx)("strong",{parentName:"p"},"Eye gaze")," : As the most important indicator of human\u2019s attention, ",(0,o.mdx)("a",{parentName:"p",href:"/docs/data_formats/mps/mps_eye_gaze"},"eye gaze direction")," estimation with uncertainty is provided by MPS. Eye gaze estimation uses the data from the eye tracking (ET) cameras."))),(0,o.mdx)("admonition",{title:"Recording profile requirement",type:"info"},(0,o.mdx)("p",{parentName:"admonition"},"To get the MPS trajectory / online calibration / semi-dense point cloud, the minimal requirement of the ",(0,o.mdx)("a",{parentName:"p",href:"/docs/tech_spec/recording_profiles"},"recording profile")," is SLAM cameras + IMU enabled.")),(0,o.mdx)("admonition",{title:"Recording profile requirement",type:"info"},(0,o.mdx)("p",{parentName:"admonition"},"To get the MPS eye gaze results, the minimal requirement of the ",(0,o.mdx)("a",{parentName:"p",href:"/docs/tech_spec/recording_profiles"},"recording profile")," is ET cameras enabled.")),(0,o.mdx)("h2",{id:"about-mps-data-loader-apis"},"About MPS Data Loader APIs"),(0,o.mdx)("p",null,"Please refer to our ",(0,o.mdx)("a",{parentName:"p",href:"/docs/data_utilities/core_code_snippets/mps#load-mps-output"},"MPS data loader APIs")," (C++ and Python support) to load the MPS outputs into your application. Additionally, the ",(0,o.mdx)("a",{parentName:"p",href:"/docs/data_utilities/visualization_guide#mps-static-scene-visualizer"},"visualization guide")," shows how to run our rich visualization tools to visualize all the MPS outputs."),(0,o.mdx)("h2",{id:"question--feedback"},"Question & Feedback"),(0,o.mdx)("p",null,"If you have feedback you'd like to provide about overall trends and experiences or improvement ideas we'd love to hear from you. Please email ",(0,o.mdx)("a",{parentName:"p",href:"mailto:AriaOps@meta.com"},"AriaOps@meta.com")," or post to the Project Aria Academic Partner Feedback and Support."))}l.isMDXComponent=!0}}]);