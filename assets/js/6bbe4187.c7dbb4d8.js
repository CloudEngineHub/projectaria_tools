"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[4513],{3905:(e,t,o)=>{o.r(t),o.d(t,{MDXContext:()=>c,MDXProvider:()=>m,mdx:()=>y,useMDXComponents:()=>p,withMDXComponents:()=>d});var a=o(67294);function i(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function r(){return r=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var o=arguments[t];for(var a in o)Object.prototype.hasOwnProperty.call(o,a)&&(e[a]=o[a])}return e},r.apply(this,arguments)}function n(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,a)}return o}function s(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?n(Object(o),!0).forEach((function(t){i(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):n(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function l(e,t){if(null==e)return{};var o,a,i=function(e,t){if(null==e)return{};var o,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)o=r[a],t.indexOf(o)>=0||(i[o]=e[o]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)o=r[a],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(i[o]=e[o])}return i}var c=a.createContext({}),d=function(e){return function(t){var o=p(t.components);return a.createElement(e,r({},t,{components:o}))}},p=function(e){var t=a.useContext(c),o=t;return e&&(o="function"==typeof e?e(t):s(s({},t),e)),o},m=function(e){var t=p(e.components);return a.createElement(c.Provider,{value:t},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},g=a.forwardRef((function(e,t){var o=e.components,i=e.mdxType,r=e.originalType,n=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(o),m=i,u=d["".concat(n,".").concat(m)]||d[m]||h[m]||r;return o?a.createElement(u,s(s({ref:t},c),{},{components:o})):a.createElement(u,s({ref:t},c))}));function y(e,t){var o=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=o.length,n=new Array(r);n[0]=g;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:i,n[1]=s;for(var c=2;c<r;c++)n[c]=o[c];return a.createElement.apply(null,n)}return a.createElement.apply(null,o)}g.displayName="MDXCreateElement"},80199:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>n,metadata:()=>l,toc:()=>d});var a=o(87462),i=(o(67294),o(3905)),r=o(79524);const n={sidebar_position:30,title:"Eye Gaze Calibration"},s="Project Aria In-Session Eye Gaze Calibration",l={unversionedId:"ARK/mps/eye_gaze_calibration",id:"ARK/mps/eye_gaze_calibration",title:"Eye Gaze Calibration",description:"Overview",source:"@site/docs/ARK/mps/eye_gaze_calibration.mdx",sourceDirName:"ARK/mps",slug:"/ARK/mps/eye_gaze_calibration",permalink:"/projectaria_tools/docs/ARK/mps/eye_gaze_calibration",draft:!1,editUrl:"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/ARK/mps/eye_gaze_calibration.mdx",tags:[],version:"current",sidebarPosition:30,frontMatter:{sidebar_position:30,title:"Eye Gaze Calibration"},sidebar:"tutorialSidebar",previous:{title:"Request MPS",permalink:"/projectaria_tools/docs/ARK/mps/request_mps"},next:{title:"ARK Release Notes",permalink:"/projectaria_tools/docs/ARK/sw_release_notes"}},c={},d=[{value:"Overview",id:"overview",level:2},{value:"What In-Session Eye Gaze Calibration does",id:"what-in-session-eye-gaze-calibration-does",level:2},{value:"How to Collect In-Session Eye Gaze Calibration",id:"how-to-collect-in-session-eye-gaze-calibration",level:2},{value:"Multiple Users Within the One Recording",id:"multiple-users-within-the-one-recording",level:3},{value:"Eye Gaze Calibration tips",id:"eye-gaze-calibration-tips",level:2},{value:"Things to avoid",id:"things-to-avoid",level:3},{value:"Things to do",id:"things-to-do",level:3}],p={toc:d},m="wrapper";function u(e){let{components:t,...n}=e;return(0,i.mdx)(m,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,i.mdx)("h1",{id:"project-aria-in-session-eye-gaze-calibration"},"Project Aria In-Session Eye Gaze Calibration"),(0,i.mdx)("h2",{id:"overview"},"Overview"),(0,i.mdx)("p",null,"This page provides an overview of what In-Session Eye Gaze Calibration does, and how to collect In-Session Eye Gaze Calibration with Project Aria glasses."),(0,i.mdx)("h2",{id:"what-in-session-eye-gaze-calibration-does"},"What In-Session Eye Gaze Calibration does"),(0,i.mdx)("p",null,"In-Session Eye Gaze Calibration enables researchers to improve the eye gaze estimations in Eye Gaze MPS outputs, enabling researchers to more accurately determine where wearers are looking during the recordings."),(0,i.mdx)("p",null,"When you request Eye Gaze Machine Perception Services (MPS) and the file has an in-session Eye Gaze Calibration as part of the VRS file, you will receive two outputs:"),(0,i.mdx)("ul",null,(0,i.mdx)("li",{parentName:"ul"},(0,i.mdx)("inlineCode",{parentName:"li"},"generalized_eye_gaze.csv")," - based on the standard eye gaze configuration"),(0,i.mdx)("li",{parentName:"ul"},(0,i.mdx)("inlineCode",{parentName:"li"},"calibrated_eye_gaze.csv")," - calibrated eye gaze data based on the calibration data collected in the recording")),(0,i.mdx)("p",null,"Every person is unique in terms of how they move their eyes and look at objects, so the calibrated_eye_gaze estimation is expected to be more accurate for the individual."),(0,i.mdx)("p",null,(0,i.mdx)("strong",{parentName:"p"},"Further resources:")),(0,i.mdx)("ul",null,(0,i.mdx)("li",{parentName:"ul"},(0,i.mdx)("a",{parentName:"li",href:"/docs/data_formats/mps/mps_eye_gaze"},"Eye Gaze Data\xa0Formats")),(0,i.mdx)("li",{parentName:"ul"},(0,i.mdx)("a",{parentName:"li",href:"/docs/ARK/mps/request_mps"},"How to Request MPS")),(0,i.mdx)("li",{parentName:"ul"},(0,i.mdx)("a",{parentName:"li",href:"/docs/ARK/glasses_manual/profile_guide#recording-profiles-that-support-mps"},"Recording Profiles That Support MPS")),(0,i.mdx)("li",{parentName:"ul"},(0,i.mdx)("a",{parentName:"li",href:"/docs/data_utilities/getting_started"},"Machine Perception Services Tutorial")," - includes sample output from a recording where good in-session Eye Gaze Calibration data was collected")),(0,i.mdx)("admonition",{type:"note"},(0,i.mdx)("p",{parentName:"admonition"},"Eye gaze calibration is not the same as Aria device calibration. For information about Aria device calibration, go to ",(0,i.mdx)("a",{parentName:"p",href:"/docs/tech_spec/device_calibration"},"Project Aria Device Calibration"),".")),(0,i.mdx)("h2",{id:"how-to-collect-in-session-eye-gaze-calibration"},"How to Collect In-Session Eye Gaze Calibration"),(0,i.mdx)("p",null,"In-Session Eye Gaze Calibration can only be initiated via the Mobile Companion App. Follow these steps for any recording where you may wish to generate Calibrated Eye Gaze MPS."),(0,i.mdx)("ol",null,(0,i.mdx)("li",{parentName:"ol"},"In the Mobile Companion app, create a new recording using a profile that includes ET and RGB cameras (such as Profile 15 or 25)"),(0,i.mdx)("li",{parentName:"ol"},"Once your recording has started, close the recording window",(0,i.mdx)("ul",{parentName:"li"},(0,i.mdx)("li",{parentName:"ul"},"Select X on the top left of the screen"))),(0,i.mdx)("li",{parentName:"ol"},"Go to Device Settings\xa0(select the gear next to your glasses)\n",(0,i.mdx)("img",{alt:"Image of how to find Project Aria glasses&#39; Device Settings page from the Dashboard",src:o(31280).Z,width:"1827",height:"917"})),(0,i.mdx)("li",{parentName:"ol"},"Select ",(0,i.mdx)("strong",{parentName:"li"},"Eye Tracking Calibration")),(0,i.mdx)("li",{parentName:"ol"},"Confirm that you\u2019d like to run it during the current recording session"),(0,i.mdx)("li",{parentName:"ol"},"Follow the prompts to calibrate your glasses")),(0,i.mdx)("h3",{id:"multiple-users-within-the-one-recording"},"Multiple Users Within the One Recording"),(0,i.mdx)("p",null,"It\u2019s possible for multiple users to do an in-session calibration within the one recording."),(0,i.mdx)("p",null,"When a new user gets the glasses, the first thing they should do is the in-session Eye Tracking Calibration."),(0,i.mdx)("ul",null,(0,i.mdx)("li",{parentName:"ul"},"See ",(0,i.mdx)("a",{parentName:"li",href:"/docs/data_formats/mps/mps_eye_gaze"},"Eye Gaze Data Format"),"\xa0for how multiple users are tracked.")),(0,i.mdx)("h2",{id:"eye-gaze-calibration-tips"},"Eye Gaze Calibration tips"),(0,i.mdx)("h3",{id:"things-to-avoid"},"Things to avoid"),(0,i.mdx)("p",null,"\u274c Do not wear a face covering during eye calibration."),(0,i.mdx)("p",null,"\u274c Choose an area with ample and even lighting; do not face a bright light, window or reflective surface."),(0,i.mdx)("p",null,"\u274c Do not set your phone screen brightness too high compared to your surroundings."),(0,i.mdx)("p",null,"\u274c Do not fully extend your arm(s) during eye calibration. Your elbows should be bent so that the phone is roughly 1 ft (30 cm) away from your face."),(0,i.mdx)("h3",{id:"things-to-do"},"Things to do"),(0,i.mdx)("p",null,"\u2705 The phone should be held straight in front of your face, so that you shouldn't look up or down to see the screen. Hold the phone plumb (90 degrees) vertically to the ground."),(0,i.mdx)("p",null,(0,i.mdx)("img",{alt:"Image of Project Aria Eye Gaze Calibration screen",src:o(27220).Z,width:"400",height:"865"})),(0,i.mdx)("p",null,'\u2705 The "Leveler" stage appears if the position of your phone isn\'t within specifications for the calibration process. Adjust the phone in front of you and its distance by bending your elbow until the smaller, black circle turns into a green disk with a check mark.'),(0,i.mdx)("p",null,(0,i.mdx)("img",{src:o(55582).Z,width:"400",height:"866"}),"\n",(0,i.mdx)("img",{src:o(73133).Z,width:"400",height:"866"}),'\n\u2705 Once the "Leveler" stage is successfully completed, do your best to keep your phone in exactly the same position throughout the full eye calibration process. If your phone is moved to a position no longer suited to calibrate your device, the app will return to the "Leveler" stage.'),(0,i.mdx)("p",null,"\u2705 During eye calibration stages 1 to 10, move your nose towards the direction indicated by the arrow. If you're only following the direction with your gaze without moving your head, the calibration stage will time out and fail. However, please make sure to keep your eyes fixed on the number within the dot the whole time."),(0,i.mdx)("p",null,(0,i.mdx)("img",{src:o(94827).Z,width:"400",height:"866"})),(0,i.mdx)("video",{width:"800",controls:!0},(0,i.mdx)("source",{src:(0,r.default)("img/ARK/eye_calibration.mp4"),type:"video/mp4"}),"Your browser does not support the video tag. Video of successful Project Aria In-Session Eye Gaze Calibration."))}u.isMDXComponent=!0},27220:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/eye_calibration-2d2e4670079aee22a15c36fcaec0996c.png"},55582:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/eye_calibration_leveler_stage-bc32b1a0e2026d29caf94661e5a2df95.png"},73133:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/eye_calibration_leveler_success-c003e1173686ce0d26a9f75077c73428.png"},94827:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/eye_calibration_pointer-68813728052ae6bc50551aed9417fdfe.jpg"},31280:(e,t,o)=>{o.d(t,{Z:()=>a});const a=o.p+"assets/images/mobile_app_device_settings-fbe834631d60e4b2bd0bce944de1ddbf.png"}}]);